{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CarelessDriving_Detection",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Eaw2Rnwo_-uBfLe67uLTFpzWoRm-AOTP",
      "authorship_tag": "ABX9TyMIjv5NPNS2EMZGBmMb75JP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reccos7/ObjectDetection_YOLO/blob/main/CarelessDriving_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "id": "2T4ZUnjVUZVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd yolov5\n",
        "# !pip install -r /content/yolov5/requirements.txt"
      ],
      "metadata": {
        "id": "m05zV_EqUtfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install FER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI_wGy9pqNFN",
        "outputId": "3353cd77-9f41-4a4d-eb96-8d3f585fc68f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting FER\n",
            "  Downloading fer-21.0.5-py3-none-any.whl (810 kB)\n",
            "\u001b[K     |████████████████████████████████| 810 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from FER) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from FER) (2.23.0)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from FER) (2.7.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from FER) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from FER) (3.2.2)\n",
            "Collecting mtcnn>=0.1.1\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from FER) (4.62.3)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn>=0.1.1->FER) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn>=0.1.1->FER) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->FER) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->FER) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->FER) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->FER) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->FER) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->FER) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->FER) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->FER) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->FER) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->FER) (2.10)\n",
            "Installing collected packages: mtcnn, FER\n",
            "Successfully installed FER-21.0.5 mtcnn-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import 설정\n",
        "\n",
        "from glob import glob\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n"
      ],
      "metadata": {
        "id": "ZBlt4ucyaDwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fer import FER\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "zVNWBt9To6q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 다렉토리 설정\n",
        "\n",
        "data_path = '/content/drive/MyDrive/careless_driving'\n",
        "train_path = data_path + '/train'\n",
        "test_path = data_path + '/test'"
      ],
      "metadata": {
        "id": "QPwds3nfU0ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 다렉토리 만들기\n",
        "\n",
        "image_directory = os.path.join(data_path, \"annotated_images\")\n",
        "if not os.path.exists(image_directory):\n",
        "     os.makedirs(image_directory)\n",
        "label_text_directory = os.path.join(data_path, \"labeled_texts\")\n",
        "if not os.path.exists(label_text_directory):\n",
        "     os.makedirs(label_text_directory)\n",
        "emotion_directory = os.path.join(data_path, \"emotions\")\n",
        "if not os.path.exists(emotion_directory):\n",
        "     os.makedirs(emotion_directory)\n",
        "boundingbox_directory = os.path.join(data_path, \"bounding_box\")\n",
        "if not os.path.exists(boundingbox_directory):\n",
        "     os.makedirs(boundingbox_directory)"
      ],
      "metadata": {
        "id": "R0HeBhn1jAXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boundingbox_directory1 = os.path.join(data_path, \"bounding_box1\")\n",
        "if not os.path.exists(boundingbox_directory1):\n",
        "     os.makedirs(boundingbox_directory1)\n",
        "boundingbox_directory2 = os.path.join(data_path, \"bounding_box2\")\n",
        "if not os.path.exists(boundingbox_directory2):\n",
        "     os.makedirs(boundingbox_directory2)"
      ],
      "metadata": {
        "id": "Yp_dt4cjO5TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_boundingbox_directory1 = os.path.join(data_path, \"yolo_bounding_box1\")\n",
        "if not os.path.exists(yolo_boundingbox_directory1):\n",
        "     os.makedirs(yolo_boundingbox_directory1)\n",
        "\n",
        "yolo_boundingbox_directory2 = os.path.join(data_path, \"yolo_bounding_box2\")\n",
        "if not os.path.exists(yolo_boundingbox_directory2):\n",
        "     os.makedirs(yolo_boundingbox_directory2)"
      ],
      "metadata": {
        "id": "B7YKNlIDbyRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨 및 이미지(bounding box) 저장\n",
        "\n",
        "names = ['eye_opened', 'eye_closed', 'mouth_opened', 'mouth_closed', 'face', 'phone', 'cigar']\n",
        "with open(train_path+'/labels.json') as f:\n",
        "    json_data = json.load(f)\n",
        "    json_anno = json_data[\"annotations\"]\n",
        "    for json_img in tqdm(json_anno):\n",
        "        img_id = str(json_img['file_name'])\n",
        "        txt_name = str(img_id.split('.')[0])+'.txt'\n",
        "        txt_dir = os.path.join(label_text_directory, txt_name)\n",
        "        img_dir = train_path + '/images/' + img_id\n",
        "        f_txt = open(txt_dir, 'w')\n",
        "        img = cv2.imread(img_dir, cv2.IMREAD_COLOR)\n",
        "        classes = []\n",
        "        for img_obj in json_img['objects']:\n",
        "            class_id = str(names.index(img_obj['class']))\n",
        "            img_pos = img_obj['position']\n",
        "            x,y,w,h = img_pos\n",
        "            img_label = img_obj['class']\n",
        "            classes.append(img_label)\n",
        "            cv2.rectangle(img,(x,y), (w,h), (0,255,0), 3)\n",
        "        for i in range(len(classes)):\n",
        "            f_txt.write('%s\\n' % classes[i])\n",
        "        cv2.imwrite(os.path.join(image_directory,img_id), img)"
      ],
      "metadata": {
        "id": "dJnUVsdmbcZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 감정 인식 저장\n",
        "with open(train_path+'/labels.json') as f:\n",
        "    json_data = json.load(f)\n",
        "    json_anno = json_data[\"annotations\"]\n",
        "    for json_img in tqdm(json_anno):\n",
        "        img_id = str(json_img['file_name'])\n",
        "        img_dir = train_path + '/images/' + img_id\n",
        "        txt_name = str(img_id.split('.')[0])+'.txt'\n",
        "        txt_dir = os.path.join(emotion_directory, txt_name)\n",
        "        f_txt = open(txt_dir, 'w')\n",
        "        img = cv2.imread(img_dir, cv2.IMREAD_COLOR)\n",
        "        emo_detector = FER(mtcnn=True)\n",
        "        captured_emotions = emo_detector.detect_emotions(img)\n",
        "        captured_emotions = 'List of emotions: '+ str(captured_emotions) +'\\n'\n",
        "        f_txt.write(captured_emotions)\n",
        "        dominant_emotion, emotion_score = emo_detector.top_emotion(img)\n",
        "        dominant_emotion = '최종 감정: '+ str(dominant_emotion)\n",
        "        f_txt.write(dominant_emotion)\n",
        "        emotion_score = ', 감정 점수: '+ str(emotion_score)\n",
        "        f_txt.write(emotion_score)"
      ],
      "metadata": {
        "id": "Vex5n3hdptej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neutral 감정 이미지 수\n",
        "\n",
        "with open(train_path+'/labels.json') as f:\n",
        "    json_data = json.load(f)\n",
        "    json_anno = json_data[\"annotations\"]\n",
        "    count = 0\n",
        "    for json_img in tqdm(json_anno):\n",
        "        img_id = str(json_img['file_name'])\n",
        "        img_dir = train_path + '/images/' + img_id\n",
        "        img = cv2.imread(img_dir, cv2.IMREAD_COLOR)\n",
        "        emo_detector = FER(mtcnn=True)\n",
        "        dominant_emotion, emotion_score = emo_detector.top_emotion(img)\n",
        "        dominant_emotion = str(dominant_emotion)\n",
        "        if dominant_emotion == 'neutral':\n",
        "            count+=1\n",
        "            print('Found {} neutral images!'.format(count))\n",
        "    print(count)"
      ],
      "metadata": {
        "id": "fj30L4J3w2-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Yolo Style로 바꾸기\n",
        "def convert(size, box): \n",
        "    dw = 1./size[0] \n",
        "    dh = 1./size[1] \n",
        "    x = (box[0] + box[1])/2.0 \n",
        "    y = (box[2] + box[3])/2.0 \n",
        "    w = box[1] - box[0] \n",
        "    h = box[3] - box[2] \n",
        "    x = x*dw \n",
        "    w = w*dw \n",
        "    y = y*dh \n",
        "    h = h*dh \n",
        "    return (x,y,w,h)\n"
      ],
      "metadata": {
        "id": "SHy_fK9_UYWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Yolo bounding box1 저장\n",
        "\n",
        "names = ['eye_opened', 'eye_closed', 'mouth_opened', 'mouth_closed', 'face', 'phone', 'cigar']\n",
        "with open(train_path+'/labels.json') as f:\n",
        "    json_data = json.load(f)\n",
        "    json_anno = json_data[\"annotations\"]\n",
        "    json_anno = json_anno[:8000]\n",
        "    for json_img in tqdm(json_anno):\n",
        "        img_id = str(json_img['file_name'])\n",
        "        txt_name = str(img_id.split('.')[0])+'.txt'\n",
        "        txt_dir = os.path.join(yolo_boundingbox_directory1, txt_name)\n",
        "        img_dir = train_path + '/images/' + img_id\n",
        "        f_txt = open(txt_dir, 'w')\n",
        "        img = cv2.imread(img_dir, cv2.IMREAD_COLOR)\n",
        "        w = img.shape[1]\n",
        "        h = img.shape[0]\n",
        "        classes = []\n",
        "        for img_obj in json_img['objects']:\n",
        "            class_id = str(names.index(img_obj['class'])) + \" \"\n",
        "            f_txt.write(class_id)\n",
        "            img_pos = img_obj['position']\n",
        "            a,b,c,d = img_pos\n",
        "            img_pos = convert((w,h),(a,c,b,d))\n",
        "            for i in range(len(img_pos)):\n",
        "                input = str(img_pos[i])\n",
        "                f_txt.write(input)\n",
        "                f_txt.write(' ')\n",
        "            f_txt.write('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHIHVxaWbI26",
        "outputId": "55199dcb-2b6f-40c5-ca9d-7d0a807cc216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8000/8000 [35:27<00:00,  3.76it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# yolo bounding box2 저장\n",
        "\n",
        "names = ['eye_opened', 'eye_closed', 'mouth_opened', 'mouth_closed', 'face', 'phone', 'cigar']\n",
        "with open(train_path+'/labels.json') as f:\n",
        "    json_data = json.load(f)\n",
        "    json_anno = json_data[\"annotations\"]\n",
        "    json_anno = json_anno[8000:]\n",
        "    for json_img in tqdm(json_anno):\n",
        "        img_id = str(json_img['file_name'])\n",
        "        txt_name = str(img_id.split('.')[0])+'.txt'\n",
        "        txt_dir = os.path.join(yolo_boundingbox_directory2, txt_name)\n",
        "        img_dir = train_path + '/images/' + img_id\n",
        "        f_txt = open(txt_dir, 'w')\n",
        "        img = cv2.imread(img_dir, cv2.IMREAD_COLOR)\n",
        "        w = img.shape[1]\n",
        "        h = img.shape[0]\n",
        "        classes = []\n",
        "        for img_obj in json_img['objects']:\n",
        "            class_id = str(names.index(img_obj['class'])) + \" \"\n",
        "            f_txt.write(class_id)\n",
        "            img_pos = img_obj['position']\n",
        "            a,b,c,d = img_pos\n",
        "            img_pos = convert((w,h),(a,c,b,d))\n",
        "            for i in range(len(img_pos)):\n",
        "                input = str(img_pos[i])\n",
        "                f_txt.write(input)\n",
        "                f_txt.write(' ')\n",
        "            f_txt.write('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CGn5JmKd7Jz",
        "outputId": "8b8f266c-8e21-43cf-9370-4b51ddaead8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8410/8410 [36:12<00:00,  3.87it/s]\n"
          ]
        }
      ]
    }
  ]
}